# -*- coding: utf-8 -*-
"""LSTM_(05.29).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19PN8sWS3rr9qvIcv6ig9uKwaQKTCqOdF
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib as mpl
import numpy as np

import tensorflow as tf
from tensorflow import keras

from keras.models import Sequential #modeli sequential yapacağız
from keras.layers import Dense, LSTM, Dropout #kullanacağımız modeller

from google.colab import drive
drive.mount('/content/gdrive')

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/data"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/data

!kaggle datasets download -d tosinabase/intel-stock-prices-historical-data-intc

!unzip \*.zip && *.zip

df = pd.read_csv(
  "INTC.csv",
  parse_dates=['Date'], 
  index_col="Date"
)

df.head()

sns.set(style='whitegrid', palette='deep', font_scale=1.3)
mpl.rcParams['figure.figsize'] = 18,8

sns.lineplot(x=df.index, y="Close", data=df); ###############################ekle

print(len(df.index.year))

train_size = int(len(df) * 0.8)
#verinin %80'inini eğitim için, kalan %20'sini test için ayırıyoruz.
test_size = len(df) - train_size
train = df[0:train_size]
test = df[train_size:len(df)]
print ("Train Shape:", train.shape,
       "\nTest Shape:", test.shape)

df.columns

from sklearn.preprocessing import StandardScaler

columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']

#creating scaler

fscaler = StandardScaler()
scaler = StandardScaler()

#fit scaler on train data

fscaler = fscaler.fit(train[columns].to_numpy())

train.loc[:, columns] = fscaler.transform(train[columns].to_numpy())

#apply transform on fitted train data

train['Close'] =  scaler.fit(train[['Close']]).transform(train[['Close']])

#fit scaler on test data

test.loc[:, columns] = fscaler.transform(test[columns].to_numpy())

#apply transform on fitted test data

test['Close'] =  scaler.fit(train[['Close']]).transform(test[['Close']])

df.shape

#### Train Data ####
time_steps = 14
train_x = []
train_y = []
for i in range(len(train) - time_steps):

  train_x.append(train.iloc[i:(i + time_steps)].values)
  train_y.append((train.Close).iloc[i + time_steps])

train_x = np.array(train_x)
train_y = np.array(train_y)

####### Test Data #######

test_x = []
test_y = []
for i in range(len(test) - time_steps):

  test_x.append(test.iloc[i:(i + time_steps)].values)
  test_y.append((test.Close).iloc[i + time_steps])

test_x = np.array(test_x)
test_y = np.array(test_y)

df.shape

print("Shape of train_x: ", train_x.shape, "\nShape of train_y: ", train_y.shape,
      "\nShape of test_x: ", test_x.shape, "\nShape of test_y:", test_y.shape)

features = 6 

model = Sequential()
model.add(LSTM(units = 5, input_shape=(time_steps, features), return_sequences=True))
model.add(Dropout(0.25))
model.add(LSTM(24))
model.add(Dense(units=1))


model.compile(loss='mean_squared_error', 
              optimizer='adam', 
              metrics=['accuracy'])

model.fit(train_x, train_y, 
          epochs=60,  
          verbose=1, 
          validation_split=0.1, 
          shuffle=False)

##############################################################################################33

test_prediction = model.predict(test_x)

plt.plot(np.arange(0, len(train_y)), train_y.flatten(), label="history")

plt.plot(np.arange(len(train_y), len(train_y) + len(test_y)), test_y.flatten(), 'g', label="true")

plt.plot(np.arange(len(train_y), len(train_y) + len(test_y)), test_prediction.flatten(), 'r', '.', label="prediction")

plt.title("Intel Stock Price Prediction ")
plt.ylabel("Close Price")
plt.xlabel("Time Step")

plt.legend()
plt.show();

plt.plot(test_y.flatten(),'g', marker='.', label="true")
plt.plot(test_prediction.flatten(), 'r', label="prediction")
plt.title("Intel Stock Price Prediction ")
plt.ylabel("Close Price")
plt.xlabel("Time Step")
plt.legend()
plt.show();